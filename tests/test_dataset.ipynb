{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/e/WPS Cloud Files/MyProject/chengxionghui/CODAS/CODAS-main/codas/utils/functions.py:17: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gym\n",
    "import os.path as osp\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from collections import deque\n",
    "\n",
    "# from configs.argments import *\n",
    "from configs.config import *\n",
    "from models.encoder_decoder import Encoder, Decoder, LargeEncoder, LargeDecoder\n",
    "from models.discriminator import TrajDiscriminator, StateDistributionDiscriminator, ImgDiscriminator\n",
    "from models.mapping_func import Real2Sim, Sim2Real, Embedding, MlpEncoder\n",
    "from models.transition import Transition, TransitionLearner, TransitionDecoder\n",
    "from models.variance_seq import VarSeq\n",
    "\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines.common.vec_env.vec_normalize import VecNormalize\n",
    "\n",
    "from utils.env_wrapper import make_vec_env, GeneratorWrapper, is_dapg_env\n",
    "from utils.transition_helper import sample_next_batch_data, sample_sim_training_data, safe_one_step_transition, obs_acs_reshape\n",
    "from utils.policy_wrapper import PolicyWrapper\n",
    "from utils.rollout import Runner\n",
    "\n",
    "from utils.mujoco_dset import Mujoco_Dset\n",
    "from utils.util import *\n",
    "from utils.replay_buffer import TrajectoryBuffer\n",
    "import mj_envs\n",
    "from reset_able_mj_env.hopper_v4 import HopperEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## argpaser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'seed': 88, 'task': '', 'env_id': 'Hopper-v4', 'auto_env_map': True, 'pretrain_path': '../data/saved_model/transition_weights.npy', 'pretrain_mean_std': '../data/saved_model/state_mean_std.npy', 'policy_timestep': 1000000, 'collect_trajs': 600, 'alg_type': 'codas', 'cycle_loss': False, 'info': '', 'traj_limitation': -1, 'expert_perf_eval_times': 100, 'action_noise_level': 0.0, 'dynamic_param': 1.0, 'load_data': '', 'load_task': '', 'max_sequence': 500, 'max_tf_util': 1.0, 'rollout_step': 25, 'minibatch_size': -1, 'dis_test': False, 'deter_policy': False, 'label_image_test': False, 'dynamic_test': False, 'use_dataset_mean_std': False, 'exact_consist': False, 'ob_transformation': 'img', 'image_size': 64, 'image_channel': 3, 'output_image': True, 'act_fn': 'LeakyReLU', 'dyn_act_fn': 'Tanh', 'layer_norm': True, 'safe_log': False, 'mapping_direction': 'rsr', 'stack_imgs': 1, 'dis_struc': '{oa}', 'rnn_cell': 'GRU', 'disc_hid_dims': [256, 256, 256], 'disc_img_hid_dims': [256], 'dyn_hid_dims': [512, 512, 512], 'disc_emb_hid_dim': 256, 'num_env': 1, 'emb_hid_dims': [256, 256, 256, 256], 'emb_output_size': 256, 'mlp': False, 'clip_acs': True, 'gan_loss': 'minimax', 'r2s_rnn_hid_dims': [128, 128], 'r2s_output_hid_dims': [], 'adjust_allowed': 1.0, 'emb_dynamic': True, 'policy_infer_transition': True, 's2r_hid_dims': [256, 256, 256, 256], 's2r_rnn_hid_dims': [], 's2r_emb_dim': 256, 'reconstruct_clip': -1, 'res_struc': '{r}{as}', 'resc_act_fn': 'Identity', 'real_ob_input': False, 'hard_training': False, 'retrain_dynamics': False, 'filter_traj': False, 'lr_gen': 0.0001, 'lr_dyn': 0.0001, 'dyn_lr_pretrain': 0.0001, 'dyn_l2_loss': 2e-07, 'mapping_l2_loss': 0.0, 'dis_l2_loss': 0.0, 'lr_dis': 5e-05, 'lr_rescale': 1.0, 'dyn_batch_size': 1024, 'mapping_train_epoch': 5, 'dis_train_epoch': 1, 'trajectory_batch': 10, 'decay_ratio': 0.5, 'total_timesteps': 40000, 'lambda_a': 2, 'lambda_b': 0.1, 'norm_std_bound': 0.05, 'stoc_init_range': 0.005, 'grad_clip_norm': 10, 'random_set_to_zero': False, 'data_normalize': True, 'minmax_normalize': False, 'npmap_replace': False, 'merge_d_train': True, 'traj_dis': True, 'clip_policy_bound': True, 'init_first_state': False, 'use_env_sample': True, 'do_save_checkpoint': True, 'pool_size': 6000, 'data_reused_times': 10, 'data_used_fraction': 1, 'use_noise_env': False, 'dual_policy_noise_std': 0.0, 'policy_trainable': False}\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "tmp = namedtuple('args', args.keys())\n",
    "args = tmp(*list(args.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.activation.LeakyReLU'> <class 'torch.nn.modules.activation.Tanh'> <class 'torch.nn.modules.linear.Identity'>\n"
     ]
    }
   ],
   "source": [
    "act_fn = getattr(nn, args.act_fn)\n",
    "resc_act_fn = getattr(nn, args.resc_act_fn)\n",
    "dyn_act_fn = getattr(nn, args.dyn_act_fn)\n",
    "rnn_cell = nn.GRU if args.rnn_cell == 'GRU' else nn.LSTM\n",
    "print(act_fn, dyn_act_fn, resc_act_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unitest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Make env and real_world_env\n",
      "\n",
      "Logging to /tmp/openai-2022-04-07-14-59-55-136801\n",
      "load Hopper environment with dynamic resacle: *1.0\n",
      "load Hopper environment with dynamic resacle: *1.0\n",
      "inner mean 0, std 1\n",
      "inner mean 0, std 1\n",
      "\n",
      "Make model\n",
      "\n",
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/codas/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/codas/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/codas/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/codas/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/codas/lib/python3.7/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/codas/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/codas/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/codas/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/codas/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.25437804e+00, -1.02531251e-03, -2.80081367e-03, -4.90458246e-03,\n",
       "       -1.32321934e-03,  2.81954387e-03,  2.31732639e-03,  1.46272567e-03,\n",
       "        1.34641158e-04,  2.83660812e-03, -3.55598799e-03])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.25010421e+00,  4.70015162e-04,  1.45830060e-03, -2.45480099e-03,\n",
       "       -2.10096443e-03, -2.50344580e-03,  4.95111847e-03, -1.41366009e-03,\n",
       "       -4.46310058e-04,  7.85754422e-04, -2.92843192e-03])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO assume the env is not robot env\n",
    "# DATA_ROOT = '/mnt/e/WPS Cloud Files/MyProject/chengxionghui/CODAS-torch/data'\n",
    "norm_std_str = '' if args.norm_std_bound == 1 else 'std-{}'.format(args.norm_std_bound)\n",
    "cpb_str = '' if args.clip_policy_bound else 'ncpb'\n",
    "img_shape = {ImgShape.WIDTH: args.image_size, ImgShape.HEIGHT: args.image_size, ImgShape.CHANNEL: 3}\n",
    "OBS_BOUND = 150 if is_dapg_env(args.env_id) else 100\n",
    "\n",
    "is_robot_env = False\n",
    "\n",
    "\n",
    "load_path = osp.join(DATA_ROOT, \"saved_model\")\n",
    "\n",
    "\n",
    "####################################################################################################################################\n",
    "#                                                                                                                                  #\n",
    "#                                                define and reset the environments                                                 #\n",
    "#                                                                                                                                  #\n",
    "####################################################################################################################################\n",
    "\n",
    "model_path = osp.join(load_path, \"ppo_{}_{}_full.zip\".format(args.env_id, args.policy_timestep))\n",
    "env_path = osp.join(load_path, \"{}_full\".format(args.env_id))\n",
    "if np.abs(args.dual_policy_noise_std - 0.0) > 1e-5:\n",
    "    real_expert_path = osp.join(\"../../../\", 'dual_{:.02f}_ppo_{}_{}_{}_deter_False_uint8.npz'.\n",
    "                            format(args.dual_policy_noise_std, args.env_id, args.policy_timestep,\n",
    "                                    args.collect_trajs))\n",
    "    sim_expert_path = osp.join(\"../../../\", 'ppo_{}_{}_full_{}_deter_False_uint8_full.npz'.\n",
    "                            format(args.env_id, args.policy_timestep, args.collect_trajs))\n",
    "else:\n",
    "    real_expert_path = sim_expert_path = osp.join(\"../../../\", 'ppo_{}_{}_full_{}_deter_False_uint8_full.npz'.\n",
    "                            format(args.env_id, args.policy_timestep, args.collect_trajs))\n",
    "print(\"\\nMake env and real_world_env\\n\")\n",
    "env = make_vec_env(args.env_id, num_env=args.num_env, dynamic_param=args.dynamic_param, stoc_init_range=args.stoc_init_range)\n",
    "env = VecNormalize.load(env_path, env)\n",
    "env.training = False\n",
    "env.norm_reward = False\n",
    "\n",
    "real_world_env = make_vec_env(args.env_id, num_env=args.num_env, dynamic_param=1.0, stoc_init_range=0.005)\n",
    "real_world_env = VecNormalize.load(env_path, real_world_env)\n",
    "real_world_env.training = False\n",
    "real_world_env.norm_reward = False\n",
    "\n",
    "env = GeneratorWrapper(env)\n",
    "real_world_env = GeneratorWrapper(real_world_env, use_image_noise=args.use_noise_env)\n",
    "\n",
    "print(\"\\nMake model\\n\")\n",
    "model = PPO2.load(model_path)\n",
    "dynamics_model_path = osp.join(load_path, f'ppo_{args.env_id}_{args.policy_timestep}_{COLLECT_TRAJ}_network_weights-full'\n",
    "                                            f'-{args.dynamic_param}-ca-{args.clip_acs}-'\n",
    "                                            f'dn-{args.data_normalize}{args.minmax_normalize}{norm_std_str}{cpb_str}')\n",
    "dynamics_model_param_path = osp.join(load_path, f'ppo_{args.env_id}_{args.policy_timestep}_{COLLECT_TRAJ}_'\n",
    "                                                f'network_weights_param-full-{ args.dynamic_param}-ca-{args.clip_acs}-'\n",
    "                                                f'dn-{args.data_normalize}{norm_std_str}{cpb_str}')\n",
    "\n",
    "if args.minmax_normalize:\n",
    "    dynamics_model_path += '-mn'\n",
    "    dynamics_model_param_path += '-mm'\n",
    "\n",
    "dynamics_model_path += '.npy'\n",
    "dynamics_model_param_path += '.pkl'\n",
    "\n",
    "runner = Runner(simulator_env=env, real_world_env=real_world_env, sim_policy=model, real_policy=model,\n",
    "                max_horizon=args.max_sequence, img_shape=img_shape, clip_acs=args.clip_acs, exact_consist=args.exact_consist)\n",
    "\n",
    "env.reset()\n",
    "real_world_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_std_str std-0.05, cpb_str , img_shape {'width': 64, 'height': 64, 'channel': 3}, OBS_BOUND 100\n",
      "env state space Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf], (11,), float64)\n",
      "env action space Box([-1. -1. -1.], [1. 1. 1.], (3,), float32)\n",
      "real_world_env state space Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf], (11,), float64)\n",
      "real_world_env action space Box([-1. -1. -1.], [1. 1. 1.], (3,), float32)\n",
      "dynamic model path:  ../data/saved_model/ppo_Hopper-v4_1000000_600_network_weights-full-1.0-ca-True-dn-TrueFalsestd-0.05.npy\n",
      "dynamic model param path:  ../data/saved_model/ppo_Hopper-v4_1000000_600_network_weights_param-full-1.0-ca-True-dn-Truestd-0.05.pkl\n",
      "real expert path:  ../../../ppo_Hopper-v4_1000000_full_600_deter_False_uint8_full.npz\n",
      "sim expert path:  ../../../ppo_Hopper-v4_1000000_full_600_deter_False_uint8_full.npz\n"
     ]
    }
   ],
   "source": [
    "print(\"norm_std_str {}, cpb_str {}, img_shape {}, OBS_BOUND {}\".format(norm_std_str, cpb_str, img_shape, OBS_BOUND))\n",
    "print(\"env state space\", env.state_space)\n",
    "print(\"env action space\", env.action_space)\n",
    "print(\"real_world_env state space\", real_world_env.state_space)\n",
    "print(\"real_world_env action space\", real_world_env.action_space)\n",
    "print(\"dynamic model path: \", dynamics_model_path)\n",
    "print(\"dynamic model param path: \", dynamics_model_param_path)\n",
    "print(\"real expert path: \", real_expert_path)\n",
    "print(\"sim expert path: \", sim_expert_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init dataset from ../../../ppo_Hopper-v4_1000000_full_600_deter_False_uint8_full.npz\n",
      "\n",
      "\n",
      "rews in dataset 2051.796689628644\n",
      "finished loading raw value\n",
      "[WARN] 0 : padding length not match current:1002, target:500\n",
      "[WARN] 0 : padding length not match current:1002, target:500\n",
      "[WARN] 0 : padding length not match current:1002, target:500\n",
      "compelte padding\n",
      "Total trajectorues: 600\n",
      "Total transitions: 600\n",
      "Average returns: 2052.540748\n",
      "Std for returns: 765.534231\n",
      "obs in ([  0.          -0.18711282  -1.59035656  -0.6252722   -0.97075045\n",
      "  -0.05207337  -4.72601723  -3.95454654  -6.87794179  -6.72959621\n",
      " -10.        ], [ 1.68136646  0.19850551  0.04823523  0.06016413  0.89405415  4.88569685\n",
      "  3.00571769  3.37718836  6.83281452  8.2080438  10.        ])\n",
      "acs in ([-1. -1. -1.], [1. 1. 1.])\n",
      "init dataset from ../../../ppo_Hopper-v4_1000000_full_600_deter_False_uint8_full.npz\n",
      "\n",
      "\n",
      "rews in dataset 1460.5678888597533\n",
      "finished loading raw value\n",
      "[WARN] 0 : padding length not match current:1002, target:500\n",
      "[WARN] 0 : padding length not match current:1002, target:500\n",
      "compelte padding\n",
      "Total trajectorues: 5600\n",
      "Total transitions: 5600\n",
      "Average returns: 1460.503984\n",
      "Std for returns: 735.456882\n",
      "obs in ([  0.          -0.1999653   -1.60420293  -0.89638663  -0.97075045\n",
      "  -0.19907292  -4.91267844  -5.01869649  -7.96349137  -7.01059624\n",
      " -10.        ], [ 1.8036612   0.19999921  0.04994327  0.06266124  0.95253388  5.26807205\n",
      "  3.29990804  5.67853525  8.24427431  8.29921822 10.        ])\n",
      "acs in ([-1. -1. -1.], [1. 1. 1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.25188926e+00, -7.89739325e-04, -4.74949155e-03,  3.57452435e-03,\n",
       "        1.59220635e-03,  2.94833424e-03,  2.32924911e-03,  2.01390590e-03,\n",
       "       -2.80451677e-03, -3.78780106e-03,  1.58052593e-03])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.25167216e+00, -1.38058307e-03, -4.13664980e-03,  9.21076363e-04,\n",
       "        2.10622128e-03,  4.22014029e-03, -4.26124867e-03, -4.11828127e-04,\n",
       "        1.31580028e-03, -6.83934065e-04,  1.43340073e-04])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_dataset = Mujoco_Dset(sim_data=False, expert_path=real_expert_path, traj_limitation=args.traj_limitation,\n",
    "                                 use_trajectory=True, max_sequence=args.max_sequence, env=env,\n",
    "                                 data_used_fraction=args.data_used_fraction, clip_action=args.clip_acs,\n",
    "                                 filter_traj=args.filter_traj, npmap_replace=args.npmap_replace)\n",
    "sim_training_dataset = Mujoco_Dset(sim_data=True, expert_path=sim_expert_path, traj_limitation=-1,\n",
    "                                use_trajectory=True, max_sequence=args.max_sequence, env=env,\n",
    "                                data_used_fraction=1.0, clip_action=args.clip_acs, filter_traj=False,\n",
    "                                    npmap_replace=args.npmap_replace)\n",
    "expert_dataset.obs_std[expert_dataset.obs_std == 0] = 1\n",
    "sim_training_dataset.obs_std[sim_training_dataset.obs_std < args.norm_std_bound] = 1\n",
    "\n",
    "state_mean_std = [sim_training_dataset.obs_mean, sim_training_dataset.obs_std]\n",
    "if not args.data_normalize:\n",
    "    state_mean_std[0] = np.zeros(state_mean_std[0].shape)\n",
    "    state_mean_std[1] = np.ones(state_mean_std[1].shape)\n",
    "\n",
    "if args.minmax_normalize:\n",
    "    state_mean_std[0] = sim_training_dataset.obs_min\n",
    "    state_mean_std[1] = sim_training_dataset.obs_max - sim_training_dataset.obs_min\n",
    "    state_mean_std[0][state_mean_std[1] == 0] = 0\n",
    "    state_mean_std[1][state_mean_std[1] == 0] = 1\n",
    "# state_mean_std = torch.FloatTensor(state_mean_std).to(DEVICE)\n",
    "env.reset()\n",
    "real_world_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_mean_std  [array([ 0.9542626 ,  0.00963413, -0.37676725, -0.04036831,  0.18012461,\n",
      "        1.71405167, -0.09029371,  0.01000815, -0.2465167 , -0.08070052,\n",
      "       -0.03574622]), array([0.58006943, 0.06046504, 0.31641538, 0.0872722 , 0.53100412,\n",
      "       1.24555214, 1.18027144, 0.75612451, 1.64034753, 1.17309253,\n",
      "       5.26985916])]\n",
      "data normalize  True\n",
      "minmax_normalize  False\n"
     ]
    }
   ],
   "source": [
    "print(\"state_mean_std \", state_mean_std)\n",
    "print(\"data normalize \", args.data_normalize)\n",
    "print(\"minmax_normalize \", args.minmax_normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrain the dynamic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the normalize range\n",
    "if args.clip_policy_bound:\n",
    "    norm_min = data_normalization(np.clip(sim_training_dataset.obs_min, -1 * OBS_BOUND, OBS_BOUND), state_mean_std)\n",
    "    norm_max = data_normalization(np.clip(sim_training_dataset.obs_max, -1 * OBS_BOUND, OBS_BOUND), state_mean_std)\n",
    "else:\n",
    "    norm_min = data_normalization(sim_training_dataset.obs_min, state_mean_std)\n",
    "    norm_max = data_normalization(sim_training_dataset.obs_max, state_mean_std)\n",
    "\n",
    "norm_range = norm_max - norm_min\n",
    "\n",
    "epsilon_expanded = 0.05\n",
    "update_dynamics_range_min = norm_min - epsilon_expanded * norm_range\n",
    "update_dynamics_range_max = norm_max + epsilon_expanded * norm_range\n",
    "update_dynamics_range_min_trans_learn = norm_min - (epsilon_expanded - 1e-3) * norm_range\n",
    "update_dynamics_range_max_trans_learn = norm_max + (epsilon_expanded - 1e-3) * norm_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_min [-1.6450834  -3.46645651 -3.87919098 -9.80860217 -2.16735619 -1.53596508\n",
      " -4.08582684 -6.65063036 -4.70447544 -5.90737349 -1.89080077], norm_max [1.46430506 3.14834958 1.34857707 1.18055395 1.45462011 2.85336941\n",
      " 2.87239158 7.49681701 5.1762147  7.14344223 1.90436707]\n",
      "[1.61977448 3.47908989 1.60996547 1.73001176 1.63571892 3.07283614\n",
      " 3.2203025  8.20418938 5.67024921 7.79598302 2.09412546] [ -1.80055282  -3.79719681  -4.14057938 -10.35805997  -2.348455\n",
      "  -1.75543181  -4.43373776  -7.35800273  -5.19850994  -6.55991427\n",
      "  -2.08055917] [1.61666509 3.47247508 1.6047377  1.7190226  1.63209694 3.06844681\n",
      " 3.21334429 8.19004193 5.66036852 7.7829322  2.09033029] [ -1.79744343  -3.79058201  -4.13535161 -10.34707082  -2.34483303\n",
      "  -1.75104247  -4.42677954  -7.34385528  -5.18862925  -6.54686346\n",
      "  -2.076764  ]\n"
     ]
    }
   ],
   "source": [
    "print(\"norm_min {}, norm_max {}\".format(norm_min, norm_max))\n",
    "print(update_dynamics_range_max, update_dynamics_range_min, update_dynamics_range_max_trans_learn, update_dynamics_range_min_trans_learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 5, 40000, 1.0, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_size = int(args.pool_size if args.pool_size > 0 else args.trajectory_batch * args.data_reused_times * 1000)\n",
    "trajecory_buffer = TrajectoryBuffer(pool_size, has_img=False)\n",
    "mapping_train_epoch = args.mapping_train_epoch\n",
    "\n",
    "total_timesteps = args.total_timesteps\n",
    "adjust_allowed = args.adjust_allowed\n",
    "discriminator_train_epochs = args.dis_train_epoch\n",
    "pool_size, mapping_train_epoch, total_timesteps, adjust_allowed, discriminator_train_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test runner run_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.75it/s]\n"
     ]
    }
   ],
   "source": [
    "rews = []\n",
    "for i in tqdm(range(args.expert_perf_eval_times)):\n",
    "    ret_dict = runner.run_traj(deter=False, mapping_holder=None, render_img=False,\n",
    "                                run_in_realworld=True)\n",
    "    while ret_dict[runner.TRAJ_LEN] == 0:\n",
    "        ret_dict = runner.run_traj(deter=False, mapping_holder=None, render_img=False,\n",
    "                                    run_in_realworld=True)\n",
    "    rews.append(ret_dict[runner.TOTAL_REW])\n",
    "expert_reward = np.mean(rews)\n",
    "\n",
    "if is_dapg_env(args.env_id):\n",
    "    if args.env_id == 'pen-v0':\n",
    "        expert_reward_lower_bound_assert = expert_dataset.avg_ret * ((args.max_sequence * 0.8) / 200)\n",
    "    else:\n",
    "        expert_reward_lower_bound_assert = expert_dataset.avg_ret * ((args.max_sequence * 0.6) / 200)\n",
    "else:\n",
    "    expert_reward_lower_bound_assert = expert_dataset.avg_ret * ((args.max_sequence * 0.8) / 1000)\n",
    "\n",
    "assert expert_reward_lower_bound_assert < expert_reward, \"dataset perf: {}, runner perf: {} < {}\".\\\n",
    "    format(expert_dataset.avg_ret, expert_reward, expert_reward_lower_bound_assert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_rew 1650.192925472934\n",
      "traj_len 499\n",
      "ob_traj (500, 11)\n",
      "ac_traj (500, 3)\n",
      "r2s_ob_traj (500, 11)\n",
      "img_traj (500, 64, 64, 3)\n",
      "dones_traj (500,)\n"
     ]
    }
   ],
   "source": [
    "for k, v in ret_dict.items():\n",
    "    if type(v) is np.ndarray:\n",
    "        print(k, v.shape)\n",
    "    else:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fba780d8950>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(ret_dict['img_traj'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expert reward  1191.7237237219113\n",
      "expert_dataset.avg_ret  2052.5407476369023\n",
      "expert_reward_lower_bound_assert  821.016299054761\n"
     ]
    }
   ],
   "source": [
    "print(\"expert reward \", expert_reward)\n",
    "print(\"expert_dataset.avg_ret \", expert_dataset.avg_ret)\n",
    "print(\"expert_reward_lower_bound_assert \", expert_reward_lower_bound_assert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the transition moodels\n",
    "if args.emb_dynamic:\n",
    "    transition = Transition(transition_hidden_dims=args.dyn_hid_dims, transition_trainable=True,\n",
    "                                        ob_shape=env.state_space.shape[0], ac_shape=env.action_space.shape[0], act_fn=dyn_act_fn,  \n",
    "                                        obs_min=update_dynamics_range_min,\n",
    "                                        obs_max=update_dynamics_range_max).to(DEVICE)\n",
    "    transition_target = Transition(transition_hidden_dims=args.dyn_hid_dims, transition_trainable=False,\n",
    "                                        ob_shape=env.state_space.shape[0], ac_shape=env.action_space.shape[0], act_fn=dyn_act_fn,  \n",
    "                                        obs_min=update_dynamics_range_min,\n",
    "                                        obs_max=update_dynamics_range_max).to(DEVICE)\n",
    "    transition_learner = TransitionLearner(transition=transition, transition_target=transition_target, \n",
    "                                            ob_shape=env.state_space.shape[0], ac_shape=env.action_space.shape[0], \n",
    "                                            lr=args.lr_dyn, batch_size=args.dyn_batch_size, l2_loss=args.dyn_l2_loss).to(DEVICE)\n",
    "    transition_decoder_input_size = args.r2s_rnn_hid_dims[-1] + env.state_space.shape[0] + 256 + env.action_space.shape[0]\n",
    "    transition_decoder = TransitionDecoder(ob_shape=env.state_space.shape[0], input_size=transition_decoder_input_size,\n",
    "                                               hidden_dims=args.r2s_output_hid_dims,\n",
    "                                               obs_min=update_dynamics_range_min,\n",
    "                                               obs_max=update_dynamics_range_max).to(DEVICE)\n",
    "else:\n",
    "    transition = None\n",
    "    transition_learner = None\n",
    "    transition_decoder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamics_model_path = './m.pkl'\n",
    "dynamics_model_param_path = './lr.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter 1\tmse_loss 0.5912\tmax_error 12.7969\tl2_reg 516.0572\n",
      "Counter 2\tmse_loss 0.0684\tmax_error 6.4876\tl2_reg 516.8673\n",
      "Counter 3\tmse_loss 0.0463\tmax_error 6.2499\tl2_reg 516.9283\n",
      "Counter 4\tmse_loss 0.0383\tmax_error 6.1379\tl2_reg 517.0185\n",
      "Counter 5\tmse_loss 0.0364\tmax_error 7.0845\tl2_reg 517.0982\n",
      "Counter 6\tmse_loss 0.0341\tmax_error 6.1722\tl2_reg 517.1525\n",
      "Counter 7\tmse_loss 0.0314\tmax_error 5.7417\tl2_reg 517.1612\n",
      "Counter 8\tmse_loss 0.0304\tmax_error 6.3774\tl2_reg 517.1764\n",
      "Counter 9\tmse_loss 0.0298\tmax_error 5.1782\tl2_reg 517.1817\n",
      "Counter 10\tmse_loss 0.0273\tmax_error 5.4623\tl2_reg 517.1894\n",
      "Counter 11\tmse_loss 0.0282\tmax_error 6.5332\tl2_reg 517.2554\n"
     ]
    }
   ],
   "source": [
    "adjust_allowed = args.adjust_allowed\n",
    "\n",
    "max_error_list = deque(maxlen=50)\n",
    "max_error_list.append(np.inf)\n",
    "inc_batch_counter = 0\n",
    "\n",
    "break_counter = 0\n",
    "inc_batch_counter = 0\n",
    "counter = 0\n",
    "while True:\n",
    "    obs_real, _, acs_real, lengths = sample_sim_training_data(args, sim_training_dataset, OBS_BOUND, state_mean_std, traj_batch_size=100)\n",
    "    obs_train, acs_train, obs_next_train = obs_acs_reshape(obs_real, acs_real)\n",
    "\n",
    "    mse_loss, max_error, l2_reg = transition_learner.update_transition(obs_train, acs_train, obs_next_train, lr=args.dyn_lr_pretrain)\n",
    "    if counter % 50 == 0:\n",
    "        transition_learner.copy_params_to_target()\n",
    "\n",
    "    inc_batch_counter = inc_batch_counter + 1 if np.min(max_error_list) <= max_error else 0\n",
    "    max_error_list.append(max_error)\n",
    "\n",
    "    if inc_batch_counter >= 200 and counter > 100000: # store the weights\n",
    "        inc_batch_counter = 0\n",
    "        transition_learner.transition.save(dynamics_model_path)\n",
    "        with open(dynamics_model_param_path, 'wb') as f:\n",
    "            pickle.dump({\"lr\": transition_learner.lr}, file=f)\n",
    "        break\n",
    "    \n",
    "    if counter > 10:\n",
    "        break\n",
    "    \n",
    "    if counter % 1000 == 1: # store the weights\n",
    "        transition_learner.transition.save(dynamics_model_path)\n",
    "        with open(dynamics_model_param_path, 'wb') as f:\n",
    "            pickle.dump({\"lr\": transition_learner.lr}, file=f)\n",
    "\n",
    "    break_counter += 1 if max_error < (adjust_allowed * 0.8)**2 else 0\n",
    "    if break_counter >= 20 and counter > 100000:\n",
    "        break\n",
    "    counter += 1\n",
    "    print(\"Counter {}\\tmse_loss {:.4f}\\tmax_error {:.4f}\\tl2_reg {:.4f}\".format(counter, mse_loss, max_error, l2_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the discriminator and generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the discriminator\n",
    "if args.gan_loss == GanLoss.MINIMAX:\n",
    "    if args.traj_dis: ## judge whether the discriminator is applied on trajectory or statedistribution\n",
    "        discriminator = TrajDiscriminator(input_size=env.state_space.shape[0]+env.action_space.shape[0], hid_dims=args.disc_hid_dims, emb_hid_dim=args.disc_emb_hid_dim, output_size=1, discre_struc=args.dis_struc, layer_norm=False, rnn_cell=rnn_cell, rnn_hidden_dims=[128]).to(DEVICE)\n",
    "    else:\n",
    "        state_dis_input_size = env.state_space.shape[0] if args.dis_struc == DiscriminatorStructure.OB else env.state_space.shape[0] + env.action_space.shape[0]\n",
    "        discriminator = StateDistributionDiscriminator(input_size=state_dis_input_size, hid_dims=args.disc_hid_dims, emb_hid_dim=args.disc_emb_hid_dim, output_size=1, discre_struc=args.dis_struc, layer_norm=False, rnn_cell=rnn_cell, rnn_hidden_dims=[128]).to(DEVICE)\n",
    "elif args.gan_loss == GanLoss.WGAN:\n",
    "    state_dis_input_size = env.state_space.shape[0] if args.dis_struc == DiscriminatorStructure.OB else env.state_space.shape[0] + env.action_space.shape[0]\n",
    "    discriminator = StateDistributionDiscriminator(input_size=state_dis_input_size, hid_dims=args.disc_hid_dims, emb_hid_dim=args.disc_emb_hid_dim, output_size=1, discre_struc=args.dis_struc, layer_norm=False, act_fn=nn.LeakyReLU).to(DEVICE)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "img_discriminator = ImgDiscriminator(input_size=img_shape[ImgShape.HEIGHT],hid_dims=args.disc_img_hid_dims, emb_hid_dim=args.disc_emb_hid_dim, output_size=1, discre_struc=args.dis_struc, layer_norm=args.layer_norm).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(stack_imgs=args.stack_imgs).to(DEVICE)\n",
    "obs_output_size = get_output_size(encoder, [args.max_sequence]+list(img_shape.values()), dims=[-1])\n",
    "ac_shape = env.action_space.shape[0]\n",
    "img_shape_to_list = [img_shape[ImgShape.WIDTH], img_shape[ImgShape.HEIGHT], img_shape[ImgShape.CHANNEL]]\n",
    "acs_output_size = ac_shape\n",
    "embedding = Embedding(input_size=obs_output_size+acs_output_size, hidden_dims=args.emb_hid_dims, output_size=args.emb_output_size, act_fn=act_fn, layer_norm=args.layer_norm).to(DEVICE)\n",
    "mlp = None # MlpEncoder(input_size=14, hidden_dims=args.dyn_hid_dims, act_fn=nn.Tanh).to(DEVICE)\n",
    "\n",
    "real2sim_input_size = 256 + env.state_space.shape[0] + env.action_space.shape[0]  if args.emb_dynamic else 256\n",
    "real2sim = Real2Sim(input_size=real2sim_input_size, rnn_hidden_dims=args.r2s_rnn_hid_dims, rnn_cell=rnn_cell, seq_length=args.max_sequence, act_fn=act_fn, ob_shape=env.state_space.shape[0], action_shape=env.action_space.shape[0], mlp_layer=mlp, output_hidden_dims=args.r2s_output_hid_dims, layer_norm=args.layer_norm, emb_dynamic=args.emb_dynamic, transition=transition, transition_decoder=transition_decoder, target_mapping=False, num_gan_step=1, device='cuda').to(DEVICE)\n",
    "\n",
    "sim2real_real_input_size = 256 if args.real_ob_input else env.state_space.shape[0]\n",
    "sim2real_real2sim_input_size = env.state_space.shape[0] + env.action_space.shape[0] if args.res_struc == ResnetStructure.EMBEDDING_RAS else env.state_space.shape[0]\n",
    "sim2real = Sim2Real(real_input_size=sim2real_real_input_size, real2sim_input_size=sim2real_real2sim_input_size, hidden_dims=args.s2r_emb_dim, rnn_hidden_dims=args.s2r_rnn_hid_dims, rnn_cell=rnn_cell, emb_dim=args.s2r_emb_dim, ob_shape=env.state_space.shape[0], ac_shape=env.action_space.shape[0], layer_norm=args.layer_norm, res_struc=args.res_struc, act_fn=resc_act_fn, real_ob_input=args.real_ob_input, device='cuda').to(DEVICE)\n",
    "\n",
    "if args.image_size == 64:\n",
    "    encoder = Encoder(stack_imgs=args.stack_imgs).to(DEVICE)\n",
    "    decoder = Decoder(input_size=256, output_size=img_shape[ImgShape.CHANNEL]).to(DEVICE)\n",
    "else:\n",
    "    assert args.image_size == 128\n",
    "    encoder = LargeEncoder(stack_imgs=args.stack_imgs).to(DEVICE)\n",
    "    decoder = LargeDecoder().to(DEVICE)\n",
    "\n",
    "\n",
    "## define the variance sequence model\n",
    "var_seq = VarSeq(sequence_length=args.max_sequence, img_shape=img_shape,\n",
    "                     embedding=embedding, real2sim_mapping=real2sim, sim2real_mapping=sim2real,\n",
    "                     discriminator=discriminator, obs_discriminator=img_discriminator,\n",
    "                     encoder=encoder, decoder=decoder,\n",
    "                     batch_size=args.trajectory_batch,\n",
    "                     lambda_a=args.lambda_a, lambda_b=args.lambda_b,\n",
    "                     ac_shape=env.action_space.shape[0], ob_shape=env.state_space.shape[0],\n",
    "                     lr_dis=args.lr_dis, lr_gen=args.lr_gen,\n",
    "                     total_timesteps=args.total_timesteps, decay_ratio=args.decay_ratio,\n",
    "                     grad_clip_norm=args.grad_clip_norm,\n",
    "                     dis_test=args.dis_test, label_image_test=args.label_image_test,\n",
    "                     reconstruct_clip=args.reconstruct_clip,\n",
    "                     emb_dynamic=args.emb_dynamic, rollout_step=args.rollout_step,\n",
    "                     cycle_loss=args.cycle_loss, minibatch_size=args.minibatch_size, merge_d_train=args.merge_d_train,\n",
    "                     stack_imgs=args.stack_imgs, random_set_to_zero=args.random_set_to_zero,\n",
    "                     init_first_state=args.init_first_state, l2_coeff=args.mapping_l2_loss,\n",
    "                     dis_l2_coeff=args.dis_l2_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### infer the correspongding trajectories via the mapping function f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.031303174793720245, 8.948004722595215, 517.3034057617188)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.02582508698105812, 4.2738871574401855, 517.307373046875)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.029064491391181946, 3.8858351707458496, 517.3107299804688)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.026794472709298134, 4.99024772644043, 517.3145141601562)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((10, 500, 11),\n",
       " (10, 500, 64, 64, 3),\n",
       " (10, 500, 3),\n",
       " [367, 452, 325, 394, 384, 499, 454, 400, 330, 479],\n",
       " (10, 500))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((10, 500, 11),\n",
       " (10, 500, 3),\n",
       " [367, 452, 325, 394, 384, 499, 454, 400, 330, 479],\n",
       " (10, 500))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 500, 267]), torch.Size([10, 500, 267]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([138, 25, 64, 64, 3]),\n",
       " torch.Size([138, 64, 64, 3]),\n",
       " torch.Size([138, 25, 3]),\n",
       " torch.Size([138, 3]),\n",
       " torch.Size([170, 25, 3]),\n",
       " torch.Size([170, 3]),\n",
       " torch.Size([170, 25, 11]),\n",
       " torch.Size([138, 25, 11]),\n",
       " torch.Size([138, 267]),\n",
       " torch.Size([138, 267]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_timesteps = args.total_timesteps\n",
    "discriminator_train_epochs = args.dis_train_epoch\n",
    "\n",
    "start_epoch = 0\n",
    "mapping_train_epochs = 20\n",
    "too_strong_discriminator = False\n",
    "for it in range(start_epoch, total_timesteps):\n",
    "    ## sample a batch of target domain trajectories real traj = {(o0,a0,o1,a1,...)} from real dataset\n",
    "    obs_real, imgs_real, acs_real, lengths, dones = sample_next_batch_data(args, runner, expert_dataset, trajecory_buffer, OBS_BOUND, state_mean_std, LossType.VAE, it)\n",
    "    obs_sim, _, acs_sim, lengths, dones = sample_next_batch_data(args, runner, expert_dataset, trajecory_buffer, OBS_BOUND, state_mean_std, LossType.GAN, it)\n",
    "    \n",
    "    ## infer the corresponding state trajectories sim traj = {(s^hat_1, ..., s^hat_T)} via the mapping function f\n",
    "    res_infer_dict = var_seq.infer_data(S_r=obs_real, O_r=imgs_real, A_r=acs_real, S_sim=obs_sim, A_sim=acs_sim, adjust_allowed=adjust_allowed)\n",
    "\n",
    "    var_length, var_length_sim = res_infer_dict['var_length'], res_infer_dict['var_length_sim']\n",
    "    all_hidden_state, all_cycle_hidden_state = res_infer_dict['all_hidden_state'], res_infer_dict['all_cycle_hidden_state']\n",
    "    ob_real2sim = res_infer_dict['hat_S_r_mask'] # core returns\n",
    "\n",
    "    # no need to perform full_state_to_state here because no obs are fed into networks\n",
    "    ## rollout one step with the oracle simulation dynamics p(s'|s, a) for each state-action pair in sim traj \n",
    "    ## to construct the transition dataset D_{s^hat}={(s^hat_i, a_i, s_{i+1})}\n",
    "    O_r_rollout, O_r_first, A_r_rollout, A_r_first, A_sim_rollout, A_sim_first, S_sim_rollout, S_r_rollout, prev_hidden_state, prev_cycle_hidden_state = var_seq.preprocess_data(S_r=obs_real, O_r=imgs_real, A_r=acs_real, S_sim=obs_sim, A_sim=acs_sim, var_length=var_length,  var_length_sim=var_length_sim, all_hidden_state=all_hidden_state, all_cycle_hidden_state=all_cycle_hidden_state)\n",
    "\n",
    "    res_discriminator_dict = var_seq.train_discriminator(O_r_rollout, O_r_first, A_r_rollout, A_r_first, A_sim_rollout, A_sim_first, S_sim_rollout, S_r_rollout, prev_hidden_state, prev_cycle_hidden_state, global_steps=it, adjust_allowed=adjust_allowed)\n",
    "\n",
    "    res_mapping_dict = var_seq.train_mapping(O_r_rollout, O_r_first, A_r_rollout, A_r_first, A_sim_rollout, A_sim_first, S_sim_rollout, S_r_rollout, prev_hidden_state, prev_cycle_hidden_state, global_steps=it, adjust_allowed=adjust_allowed)\n",
    "\n",
    "    if args.emb_dynamic:\n",
    "        obs_sim_dyn, _, acs_sim_dyn, _ = sample_sim_training_data(args, sim_training_dataset, OBS_BOUND, state_mean_std)\n",
    "        ob_real2sim_trans = ob_real2sim.reshape((-1, ob_real2sim.shape[-1]))\n",
    "        de_normalize_ob_trans = data_denormalization(ob_real2sim_trans, state_mean_std)\n",
    "        if not is_robot_env:\n",
    "            policy_infer_acs = model.step(de_normalize_ob_trans, deterministic=args.deter_policy)[0]\n",
    "\n",
    "            policy_infer_acs = np.clip(policy_infer_acs, env.action_space.low, env.action_space.high) if args.clip_acs else policy_infer_acs\n",
    "            policy_infer_acs = np.reshape(policy_infer_acs,  list(ob_real2sim.shape[:2]) + [acs_real.shape[-1]])\n",
    "\n",
    "            acs_dyn_train = np.concatenate([acs_sim_dyn, acs_real, policy_infer_acs], axis=0)\n",
    "            obs_dyn_train = np.concatenate([obs_sim_dyn, ob_real2sim.cpu().numpy(), ob_real2sim.cpu().numpy()], axis=0)\n",
    "            obs_input, acs_input, next_obs_input, full_states, _ = safe_one_step_transition(args, env, is_robot_env, obs_dyn_train, acs_real, acs_dyn_train, update_dynamics_range_min_trans_learn, update_dynamics_range_max_trans_learn, state_mean_std)\n",
    "        ## update dynamics model\n",
    "        if obs_input.shape[0] != 0:\n",
    "            transition_learner.update_transition(obs_input, acs_input, next_obs_input)\n",
    "        transition_learner.copy_params_to_target()\n",
    "    \n",
    "    if it > 2:\n",
    "        break\n",
    "    \n",
    "obs_real.shape, imgs_real.shape, acs_real.shape, lengths, dones.shape\n",
    "obs_sim.shape, acs_sim.shape, lengths, dones.shape\n",
    "all_hidden_state.shape, all_cycle_hidden_state.shape\n",
    "O_r_rollout.shape, O_r_first.shape, A_r_rollout.shape, A_r_first.shape, A_sim_rollout.shape, A_sim_first.shape, S_sim_rollout.shape, S_r_rollout.shape, prev_hidden_state.shape, prev_cycle_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_real[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-2.4132e-02,  2.2385e-01, -2.9307e-01,  ..., -4.3165e+09,\n",
       "          2.5809e+09,  2.3602e+09],\n",
       "        [-2.3573e-01,  1.6855e-01, -3.2696e-01,  ...,  1.7125e+09,\n",
       "         -7.2913e+09,  6.3132e+08],\n",
       "        ...,\n",
       "        [-7.5565e-02,  2.8521e-01, -1.8212e-01,  ..., -4.5622e+09,\n",
       "         -1.0003e+09, -2.0430e+08],\n",
       "        [ 1.1951e-01,  5.6005e-01, -2.9911e-01,  ...,  3.7454e+08,\n",
       "         -8.3582e+09, -3.0962e+09],\n",
       "        [ 9.5984e-03,  6.6912e-01, -1.7107e-01,  ..., -3.1666e+09,\n",
       "         -3.2086e+09, -1.4755e+09]], device='cuda:0', grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_discriminator_dict = var_seq.train_discriminator(O_r_rollout, O_r_first, A_r_rollout, A_r_first, A_sim_rollout, A_sim_first, S_sim_rollout, S_r_rollout, prev_hidden_state, prev_cycle_hidden_state, global_steps=it, adjust_allowed=adjust_allowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dis_accuracy_real torch.Size([3691, 1])\n",
      "dis_accuracy_fake torch.Size([3629, 1])\n"
     ]
    }
   ],
   "source": [
    "for k, v in res_discriminator_dict.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mapping_dict = var_seq.train_mapping(O_r_rollout, O_r_first, A_r_rollout, A_r_first, A_sim_rollout, A_sim_first, S_sim_rollout, S_r_rollout, prev_hidden_state, prev_cycle_hidden_state, global_steps=it, adjust_allowed=adjust_allowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_input:  (1399, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.024035552516579628, 3.9777162075042725, 516.0486450195312)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if args.emb_dynamic:\n",
    "    obs_sim_dyn, _, acs_sim_dyn, _ = sample_sim_training_data(args, sim_training_dataset, OBS_BOUND, state_mean_std)\n",
    "    ob_real2sim_trans = ob_real2sim.reshape((-1, ob_real2sim.shape[-1]))\n",
    "    de_normalize_ob_trans = data_denormalization(ob_real2sim_trans, state_mean_std)\n",
    "    if not is_robot_env:\n",
    "        policy_infer_acs = model.step(de_normalize_ob_trans, deterministic=args.deter_policy)[0]\n",
    "\n",
    "        policy_infer_acs = np.clip(policy_infer_acs, env.action_space.low, env.action_space.high) if args.clip_acs else policy_infer_acs\n",
    "        policy_infer_acs = np.reshape(policy_infer_acs,  list(ob_real2sim.shape[:2]) + [acs_real.shape[-1]])\n",
    "\n",
    "        acs_dyn_train = np.concatenate([acs_sim_dyn, acs_real, policy_infer_acs], axis=0)\n",
    "        obs_dyn_train = np.concatenate([obs_sim_dyn, ob_real2sim.cpu().numpy(), ob_real2sim.cpu().numpy()], axis=0)\n",
    "        obs_input, acs_input, next_obs_input, full_states, _ = safe_one_step_transition(args, env, is_robot_env, obs_dyn_train, acs_real, acs_dyn_train, update_dynamics_range_min_trans_learn, update_dynamics_range_max_trans_learn, state_mean_std)\n",
    "    ## update dynamics model\n",
    "    if obs_input.shape[0] != 0:\n",
    "        transition_learner.update_transition(obs_input, acs_input, next_obs_input)\n",
    "    transition_learner.copy_params_to_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 500, 11), (10, 500, 3))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 500, 11]), torch.Size([5000, 11]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 11)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10, 500, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((30, 500, 3), (30, 500, 11))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_sim_dyn.shape, acs_sim_dyn.shape\n",
    "ob_real2sim.shape, ob_real2sim_trans.shape\n",
    "de_normalize_ob_trans.shape\n",
    "policy_infer_acs.shape\n",
    "acs_dyn_train.shape, obs_dyn_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5a61045cc9b054f72d1f8b73daced1bed711bda5f738c54336b2edb5d092e48"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('codas')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
